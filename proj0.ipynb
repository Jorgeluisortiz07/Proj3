{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codigo para pre-filtar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46f2cc8a5770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Convert each frame to grayscale, hsv and Lab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Convertir cada frame a formato gray, hsv y Lab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mhsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mLab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2Lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# importar librerias de os, opencv, numpy y matplotlib\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#se pretende llamar el video, obtener de este solo 10 frames por segundo. \n",
    "#cada frame convertirlo a formato gray, hsv y Lab.\n",
    "#aplicar una limiarizacion y detectar bordes para identificar burbuas y partes de material.\n",
    "\n",
    "#create the folders where the results will be\n",
    "#crear carpetas donde van a estar los resultados\n",
    "os.chdir('/home/jorge/Documents')\n",
    "os.mkdir('underwater_welding_arc_bubble')\n",
    "os.chdir('/home/jorge/Documents/underwater_welding_arc_bubble')\n",
    "os.mkdir('1_ori_10fxs')\n",
    "os.mkdir('2_gray')\n",
    "os.mkdir('3_hsv')\n",
    "os.mkdir('4_Lab')\n",
    "os.mkdir('5_Lim_adapt_mean')\n",
    "os.mkdir('6_Lim_adapt_gaus')\n",
    "os.mkdir('7_otsu')\n",
    "os.mkdir('8_canny')\n",
    "os.mkdir('9_equ_adapt')\n",
    "os.mkdir('10_bin_equ_adapt')\n",
    "\n",
    "\n",
    "# leer el video desde la ubicacion del archivo (video esta en formato .MP4)\n",
    "cap = cv2.VideoCapture('/home/jorge/Documents/bRASIL/investigación/Videos e Sinais Douglas TG/MP4/5.mp4')\n",
    "\n",
    "# Check if video opened successfully\n",
    "# asegurarse de que el video se abra satisfactoriamente\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"error al abrir el video\")\n",
    "    print(\"Unable to read video feed\")\n",
    "\n",
    "\n",
    "# inicializar contadores\n",
    "i=0\n",
    "j=0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    # Capturar frame por frame\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    # Convert each frame to grayscale, hsv and Lab\n",
    "    # Convertir cada frame a formato gray, hsv y Lab\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    Lab = cv2.cvtColor(frame, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    # Apply Canny Edge Detector, adaptiveThreshold mean and adaptiveThreshold gaussian\n",
    "    # Aplicar Canny para deteccion de bordes, \n",
    "    #limiarizacion adaptativa media y limiarizacion adaptativa media   \n",
    "    adp_mean = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,     \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);  \n",
    "    adp_gau = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);\n",
    "    ret,otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
    "    canny = cv2.Canny(frame,100,200)\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(100,100))\n",
    "    cla1 = clahe.apply(gray)\n",
    "    \n",
    "    limiar, imgLimiar = cv2.threshold(gray, 200, 255, cv2.THRESH_TOZERO_INV)\n",
    "    \n",
    "    clahe2 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(100,100))\n",
    "    cla2 = clahe2.apply(imgLimiar)\n",
    "    \n",
    "    \n",
    "    # Display the resulting frames in color, gayscale, hsv, Lab, canny, adp_mean y adp_gau formats\n",
    "    # imprimir el resultado de cada frame a formato original, gray, hsv, Lab, \n",
    "    #canny, adp_mean y adp_gau\n",
    "    cv2.namedWindow(\"frame_color\")\n",
    "    cv2.imshow(\"frame_color\",frame)\n",
    "    \n",
    "    cv2.namedWindow(\"frame_gray\")\n",
    "    cv2.imshow(\"frame_gray\",gray)\n",
    "    \n",
    "    cv2.namedWindow(\"frame_hsv\")\n",
    "    cv2.imshow(\"frame_hsv\",hsv)\n",
    "    \n",
    "    cv2.namedWindow(\"frame_Lab\")\n",
    "    cv2.imshow(\"frame_Lab\",Lab)\n",
    "    \n",
    "    cv2.namedWindow(\"frame_canny\")\n",
    "    cv2.imshow(\"frame_canny\",canny)\n",
    "    \n",
    "    cv2.namedWindow(\"frame_adp_mean\")\n",
    "    cv2.imshow(\"frame_adp_mean\",adp_mean)\n",
    "    \n",
    "    cv2.namedWindow(\"frame_adp_gau\")\n",
    "    cv2.imshow(\"frame_adp_gau\",adp_gau)\n",
    "    \n",
    "    # Save images every 3 frames captured by the video .tif format\n",
    "    #(it is needed 10frames/s and the video has 30frames/s)\n",
    "    #guardar imagenes cada 3 frames, formato .tif\n",
    "    #(necesitamos 10fr/s y el video tiene 30fr/s)\n",
    "    if i == (j*3):\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/1_ori_10fxs/image'+str(j)+'.tif', frame)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/2_gray/image'+str(j)+'.tif', gray)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/3_hsv/image'+str(j)+'.tif', hsv)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/4_Lab/image'+str(j)+'.tif', Lab)   \n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/5_Lim_adapt_mean/image'+str(j)+'.tif', adp_mean)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/6_Lim_adapt_mean/image'+str(j)+'.tif', adp_gau)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/7_otsu/image'+str(j)+'.tif', otsu)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/8_canny/image'+str(j)+'.tif', canny)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/9_equ_adapt/image'+str(j)+'.tif', cla1)\n",
    "        cv2.imwrite('/home/jorge/Documents/underwater_welding_arc_bubble/10_bin_equ_adapt/image'+str(j)+'.tif', cla2)        \n",
    "        j += 1\n",
    "        \n",
    "    # Press \"q\" to quit\n",
    "    # Presione \"q\" para interrumpir\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    i += 1\n",
    "# When everything done, release the capture and destroy all windows\n",
    "# Cuando haya terminado, entregar el video y destruir todas las carpetas \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Uma vez salvadas as imagens na pasta especificada anteriormente, \n",
    "as imagens podem ser mostradas da seguinte forma:\n",
    "# Show images contained in the folder\n",
    "\n",
    "\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "img1w = glob.glob('Images_ponto_1/image*.tif')\n",
    "for x in range(len(img1w)):\n",
    "    img11 = mpimg.imread('Images_ponto_1/image%d.tif' % (x))\n",
    "    plt.title('image%d.tif' % (x), size=16)\n",
    "    plt.imshow(img11, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture('/home/jorge/Documents/bRASIL/investigación/Videos e Sinais Douglas TG/MP4/5.mp4')\n",
    "if (cap.isOpened() == False): \n",
    "    print(\"error al abrir el video\")\n",
    "    print(\"Unable to read video feed\")\n",
    "i=0\n",
    "j=0\n",
    "while(True):        \n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "    Lab = cv2.cvtColor(frame, cv2.COLOR_BGR2Lab)\n",
    "    canny = cv2.Canny(frame,100,200)\n",
    "    adp_mean = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_MEAN_C,     \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);  \n",
    "    adp_gau = cv2.adaptiveThreshold(frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n",
    "                                 cv2.THRESH_BINARY, 11, 2);\n",
    "    if i == (j*3):\n",
    "        cv2.imwrite('/home/jorge/test_gray/image'+str(j)+'.tif', gray)\n",
    "        cv2.imwrite('/home/jorge/test_hsv/image'+str(j)+'.tif', hsv)\n",
    "        cv2.imwrite('/home/jorge/test_Lab/image'+str(j)+'.tif', Lab)\n",
    "        cv2.imwrite('/home/jorge/test_canny/image'+str(j)+'.tif', edges)\n",
    "        cv2.imwrite('/home/jorge/test_adp_mean/image'+str(j)+'.tif', adp_mean)\n",
    "        cv2.imwrite('/home/jorge/test_adp_gau/image'+str(j)+'.tif', adp_gau)       \n",
    "        j += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    i += 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#esta se usara para ecualizacion del histograma\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1w = glob.glob('/home/jorge/graygray/*.tif')\n",
    "for x in range(len(img1w)):\n",
    "    img11 = mpimg.imread('/home/jorge/graygray/image%d.tif' % (x))\n",
    "    equ = cv2.equalizeHist(img11)\n",
    "    plt.title('imaget%d.tif' % (x), size=16)\n",
    "    plt.imshow(img11, cmap='gray')\n",
    "    #plt.imshow(equ,cmap = 'gray')\n",
    "    plt.imsave(\"/home/jorge/graygray/imaget%d.tif\" % (x), equ)\n",
    "    #res = np.hstack((img11,equ)) #stacking images side-by-side\n",
    "    cv2.imwrite('res%d.png' % (x),equ)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer ecualizacion del histograma adaptativa\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('/home/jorge/Downloads/mario.png',0)\n",
    "\n",
    "# create a CLAHE object (Arguments are optional).\n",
    "clahe2 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(100,100))\n",
    "cl1 = clahe2.apply(img)\n",
    "\n",
    "cv2.imwrite('cma0.jpg',cl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#esta se usara para cambiar los bits de v del hsv\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = glob.glob('/home/jorge/graygray/*.tif')\n",
    "for x in range(len(img1)):\n",
    "    img2 = mpimg.imread('/home/jorge/graygray/image%d.tif' % (x))\n",
    "    #equ = cv2.equalizeHist(img2)\n",
    "    #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    #clah = clahe.apply(img2)\n",
    "    #plt.title('imaget%d.tif' % (x), size=16)\n",
    "    #plt.imshow(img2, cmap='gray')\n",
    "    imgray2brg = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "    hsv_img = cv2.cvtColor(imgray2brg, cv2.COLOR_BGR2HSV)\n",
    "    hsv_img[:,:,2]=0\n",
    "    cv2.imwrite('/home/jorge/res_hsv/hv_%d.png' % (x),hsv_img)\n",
    "    #plt.imshow(equ,cmap = 'gray')\n",
    "    #plt.imsave(\"/home/jorge/graygray/imaget%d.tif\" % (x), equ)\n",
    "    #res = np.hstack((img11,equ)) #stacking images side-by-side\n",
    "    \n",
    "    \n",
    "    #cv2.imwrite('/home/jorge/res_hsv/res%d.png' % (x),equ)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta se usara para cambiar los bits de v del hsv (una sola imagen) \n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img2 = cv2.imread('/home/jorge/test_hsv/image0.tif')\n",
    "img2[:,:,1]=0\n",
    "cv2.imwrite('/home/jorge/res_hsv/hv_000.png',img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esta se usara limitar los pixeles de brillo \n",
    "#para aplicar ecualizacion normal y clahe a diferentes parametros\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = glob.glob('/home/jorge/graygray/*.tif')\n",
    "for x in range(len(img1)):\n",
    "    img2 = mpimg.imread('/home/jorge/graygray/image%d.tif' % (x))\n",
    "    \n",
    "    limiar, imgLimiar = cv2.threshold(img2, 200, 255, cv2.THRESH_TOZERO_INV)\n",
    "    #cv2.imwrite('bina2.png',imgLimiar)\n",
    "    limiar2, imgLimiar2 = cv2.threshold(img2, 120, 255, cv2.THRESH_TRUNC)\n",
    "\n",
    "    cv2.imwrite('/home/jorge/res_hsv/imglimi_%d.tif' % (x),imgLimiar)\n",
    "    cv2.imwrite('/home/jorge/res_hsv/imglimit_%d.tif' % (x),imgLimiar2)\n",
    "    \n",
    "\"\"\"   \n",
    "    equ = cv2.equalizeHist(imgLimiar)\n",
    "    \n",
    "    clahe1 = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    clah1 = clahe1.apply(imgLimiar)\n",
    "    \n",
    "    clahe2 = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(80,80))\n",
    "    clah2 = clahe2.apply(imgLimiar)\n",
    "    \n",
    "    clahe3 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(80,80))\n",
    "    clah3 = clahe3.apply(imgLimiar)\n",
    "    \n",
    "    clahe4 = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(100,100))\n",
    "    clah4 = clahe4.apply(imgLimiar)\n",
    "    \n",
    "    clahe5 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(100,100))\n",
    "    clah5 = clahe5.apply(imgLimiar)\n",
    "\"\"\" \n",
    "\"\"\" \n",
    "    cv2.imwrite('/home/jorge/ecu/equ_lim%d.png' % (x),equ)   \n",
    "    cv2.imwrite('/home/jorge/clah28x8/clah_2.0_8x8_%d.png' % (x),clah1)\n",
    "    cv2.imwrite('/home/jorge/clah380x80/clah_3.0_80x80_%d.png' % (x),clah2)\n",
    "    cv2.imwrite('/home/jorge/clah480x80/clah_4.0_80x80_%d.png' % (x),clah3)\n",
    "    cv2.imwrite('/home/jorge/clah3100x100/clah_3.0_100x100_%d.png' % (x),clah4)\n",
    "    cv2.imwrite('/home/jorge/clah4100x100/clah_4.0_100x100_%d.png' % (x),clah5)\n",
    "\"\"\" \n",
    "\n",
    "    #res = np.hstack((img11,equ)) #stacking images side-by-side\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jorge')\n",
    "os.mkdir('underwater_welding_arc_bubble')\n",
    "os.chdir('/home/jorge/underwater_welding_arc_bubble')\n",
    "os.mkdir('bbbbb')\n",
    "os.mkdir('cccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
